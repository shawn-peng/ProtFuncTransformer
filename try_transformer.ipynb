{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71e47699-dfa0-47a4-835b-83ebbf308b56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71d0349f-9498-41e3-8bf1-df7d90bc51cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n"
     ]
    }
   ],
   "source": [
    "from toy_transformer import Transformer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1831cad-7dea-45ac-9529-dc0f82292afd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b3e200e-fbbe-41a0-9d8a-281efbe45404",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>de</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i want to eat bread</td>\n",
       "      <td>ich mochten brot essen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i want to eat apple</td>\n",
       "      <td>ich mochten apfel essen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i want to drink water</td>\n",
       "      <td>ich mochten wasser trinken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i want to drink beer</td>\n",
       "      <td>ich mochten bier trinken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i want to read book</td>\n",
       "      <td>ich mochten buch lesen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>i want to read newspaper</td>\n",
       "      <td>ich mochten zeitung lesen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>i can eat bread</td>\n",
       "      <td>ich konnen brot essen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>i can eat apple</td>\n",
       "      <td>ich konnen apfel essen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>i can drink water</td>\n",
       "      <td>ich konnen wasser trinken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>i can drink beer</td>\n",
       "      <td>ich konnen bier trinken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>i can read book</td>\n",
       "      <td>ich konnen buch lesen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>i can read newspaper</td>\n",
       "      <td>ich konnen zeitung lesen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>we want to eat bread</td>\n",
       "      <td>wir mochten brot essen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>we want to eat apple</td>\n",
       "      <td>wir mochten apfel essen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>we want to drink water</td>\n",
       "      <td>wir mochten wasser trinken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>we want to drink beer</td>\n",
       "      <td>wir mochten bier trinken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>we want to read book</td>\n",
       "      <td>wir mochten buch lesen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>we want to read newspaper</td>\n",
       "      <td>wir mochten zeitung lesen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>we can eat bread</td>\n",
       "      <td>wir konnen brot essen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>we can eat apple</td>\n",
       "      <td>wir konnen apfel essen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>we can drink water</td>\n",
       "      <td>wir konnen wasser trinken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>we can drink beer</td>\n",
       "      <td>wir konnen bier trinken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>we can read book</td>\n",
       "      <td>wir konnen buch lesen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>we can read newspaper</td>\n",
       "      <td>wir konnen zeitung lesen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>i eat bread</td>\n",
       "      <td>ich essen brot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>i eat apple</td>\n",
       "      <td>ich essen apfel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>i drink water</td>\n",
       "      <td>ich trinken wasser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>i drink beer</td>\n",
       "      <td>ich trinken bier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>i read book</td>\n",
       "      <td>ich lesen buch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>i read newspaper</td>\n",
       "      <td>ich lesen zeitung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>we eat bread</td>\n",
       "      <td>wir essen brot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>we eat apple</td>\n",
       "      <td>wir essen apfel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>we drink water</td>\n",
       "      <td>wir trinken wasser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>we drink beer</td>\n",
       "      <td>wir trinken bier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>we read book</td>\n",
       "      <td>wir lesen buch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>we read newspaper</td>\n",
       "      <td>wir lesen zeitung</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           en                          de\n",
       "0         i want to eat bread      ich mochten brot essen\n",
       "1         i want to eat apple     ich mochten apfel essen\n",
       "2       i want to drink water  ich mochten wasser trinken\n",
       "3        i want to drink beer    ich mochten bier trinken\n",
       "4         i want to read book      ich mochten buch lesen\n",
       "5    i want to read newspaper   ich mochten zeitung lesen\n",
       "6             i can eat bread       ich konnen brot essen\n",
       "7             i can eat apple      ich konnen apfel essen\n",
       "8           i can drink water   ich konnen wasser trinken\n",
       "9            i can drink beer     ich konnen bier trinken\n",
       "10            i can read book       ich konnen buch lesen\n",
       "11       i can read newspaper    ich konnen zeitung lesen\n",
       "12       we want to eat bread      wir mochten brot essen\n",
       "13       we want to eat apple     wir mochten apfel essen\n",
       "14     we want to drink water  wir mochten wasser trinken\n",
       "15      we want to drink beer    wir mochten bier trinken\n",
       "16       we want to read book      wir mochten buch lesen\n",
       "17  we want to read newspaper   wir mochten zeitung lesen\n",
       "18           we can eat bread       wir konnen brot essen\n",
       "19           we can eat apple      wir konnen apfel essen\n",
       "20         we can drink water   wir konnen wasser trinken\n",
       "21          we can drink beer     wir konnen bier trinken\n",
       "22           we can read book       wir konnen buch lesen\n",
       "23      we can read newspaper    wir konnen zeitung lesen\n",
       "24                i eat bread              ich essen brot\n",
       "25                i eat apple             ich essen apfel\n",
       "26              i drink water          ich trinken wasser\n",
       "27               i drink beer            ich trinken bier\n",
       "28                i read book              ich lesen buch\n",
       "29           i read newspaper           ich lesen zeitung\n",
       "30               we eat bread              wir essen brot\n",
       "31               we eat apple             wir essen apfel\n",
       "32             we drink water          wir trinken wasser\n",
       "33              we drink beer            wir trinken bier\n",
       "34               we read book              wir lesen buch\n",
       "35          we read newspaper           wir lesen zeitung"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toydata = pd.read_csv('medium_articles/eng_de.csv', header=None, names=['en', 'de'])\n",
    "toydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8416189a-d40b-47ea-988e-789c23a06404",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gen_ufunc(nin, nout):\n",
    "    return lambda f: np.frompyfunc(f, nin, nout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c408aa01-3d45-46f0-a600-7689dec8e09e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reduce(f, arr, dims):\n",
    "    r = arr\n",
    "    for dim in dims:\n",
    "        r = f.reduce(r, dim, keepdims=True)\n",
    "    return r.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f772226e-77db-4c96-8ff7-72b0b1ef2f3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf78669-6579-4d10-89f1-972264417e31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6374d99a-8bf5-4067-8cb9-9402b0c3d2a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def gen_collect_func(f):\n",
    "    @gen_ufunc(1, 1)\n",
    "    def collect_cell(cell):\n",
    "        return f(cell)\n",
    "    return collect_cell\n",
    "    \n",
    "def collect_cell(df, f):\n",
    "    res = reduce(gen_collect_func(f), df.to_numpy(), [0, 1])\n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dae0680d-1f07-45d7-8686-c7709803ccb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab = toydata.applymap(lambda x: x.split()).apply(np.sum).apply(set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15d00c1b-02ee-4dad-9bba-d7bf30b3e376",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "src_vocab_size = len(vocab['en'])\n",
    "target_vocab_size = len(vocab['de'])\n",
    "num_layers = 6\n",
    "seq_length= 12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42c19964-a99f-4c6b-8595-1ef6b6403f84",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder): TransformerEncoder(\n",
       "    (embedding_layer): Embedding(\n",
       "      (embed): Embedding(14, 512)\n",
       "    )\n",
       "    (positional_encoder): PositionalEmbedding()\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x TransformerBlock(\n",
       "        (attention): MultiHeadAttention(\n",
       "          (query_matrix): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (key_matrix): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (value_matrix): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (out): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (feed_forward): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): TransformerDecoder(\n",
       "    (word_embedding): Embedding(13, 512)\n",
       "    (position_embedding): PositionalEmbedding()\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x DecoderBlock(\n",
       "        (attention): MultiHeadAttention(\n",
       "          (query_matrix): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (key_matrix): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (value_matrix): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (out): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (transformer_block): TransformerBlock(\n",
       "          (attention): MultiHeadAttention(\n",
       "            (query_matrix): Linear(in_features=64, out_features=64, bias=False)\n",
       "            (key_matrix): Linear(in_features=64, out_features=64, bias=False)\n",
       "            (value_matrix): Linear(in_features=64, out_features=64, bias=False)\n",
       "            (out): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Sequential(\n",
       "            (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout1): Dropout(p=0.2, inplace=False)\n",
       "          (dropout2): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fc_out): Linear(in_features=512, out_features=13, bias=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Transformer(embed_dim=512, src_vocab_size=src_vocab_size, \n",
    "                    target_vocab_size=target_vocab_size, seq_length=seq_length,\n",
    "                    num_layers=num_layers, expansion_factor=4, n_heads=8)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0342934f-01c9-4154-a2b3-8b02c179519a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.core.magic import (register_line_magic, register_cell_magic,\n",
    "                                register_line_cell_magic)\n",
    "\n",
    "@register_line_magic\n",
    "def print_var(var):\n",
    "    return print(var, eval(var))\n",
    "\n",
    "@register_cell_magic\n",
    "def skip(line, cell):\n",
    "    \"my cell magic\"\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bac138c9-e7a0-46ca-984f-8498d1921649",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "pip install -U torchdata\n",
    "pip install -U spacy\n",
    "python -m spacy download en_core_web_sm\n",
    "python -m spacy download de_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94e3c61a-82ca-4065-817e-a4da4a1e2df2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.datasets import multi30k, Multi30k\n",
    "from typing import Iterable, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a4afb67-a262-4e4a-9359-29cc4a005488",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We need to modify the URLs for the dataset since the links to the original dataset are broken\n",
    "# Refer to https://github.com/pytorch/text/issues/1756#issuecomment-1163664163 for more info\n",
    "multi30k.URL[\"train\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/training.tar.gz\"\n",
    "multi30k.URL[\"valid\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/validation.tar.gz\"\n",
    "\n",
    "TGT_LANGUAGE = 'de'\n",
    "SRC_LANGUAGE = 'en'\n",
    "\n",
    "# Place-holders\n",
    "token_transform = {}\n",
    "vocab_transform = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5492ff81-1b04-455b-9d3e-a671cf1a184c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='de_core_news_sm')\n",
    "token_transform[TGT_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef608d75-cd17-4b83-9d67-e8fe8da5cbfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n",
    "    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
    "\n",
    "    for data_sample in data_iter:\n",
    "        yield token_transform[language](data_sample[language_index[language]])\n",
    "def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n",
    "    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
    "\n",
    "    for i, data_sample in data_iter:\n",
    "        yield token_transform[language](data_sample[language])\n",
    "\n",
    "# Define special symbols and indices\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
    "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
    "\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    # Training data Iterator\n",
    "    # train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "    train_iter = toydata.iterrows()\n",
    "    \n",
    "    # Create torchtext's Vocab object\n",
    "    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train_iter, ln),\n",
    "                                                    min_freq=1,\n",
    "                                                    specials=special_symbols,\n",
    "                                                    special_first=True)\n",
    "\n",
    "# Set ``UNK_IDX`` as the default index. This index is returned when the token is not found.\n",
    "# If not set, it throws ``RuntimeError`` when the queried token is not found in the Vocabulary.\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    vocab_transform[ln].set_default_index(UNK_IDX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52713707-746b-423a-a275-e4c86ed218f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%skip\n",
    "pip install portalocker>=2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da2718a4-a2d5-4e2b-9f75-97822b808ddc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d96757f-23f6-4739-b346-ce822df9e099",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34304df5-a822-4209-bcdd-201524484a8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
    "TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
    "EMB_SIZE = 512\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "BATCH_SIZE = 128\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3\n",
    "\n",
    "# transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
    "#                                  NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
    "model = Transformer(embed_dim=512, src_vocab_size=SRC_VOCAB_SIZE, \n",
    "                    target_vocab_size=TGT_VOCAB_SIZE, seq_length=seq_length,\n",
    "                    num_layers=3, expansion_factor=4, n_heads=8)\n",
    "transformer = model\n",
    "\n",
    "for p in transformer.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "transformer = transformer.to(DEVICE)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "afc04ffe-ffda-468f-a3f0-883d1c7dbb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_transform(tokens):\n",
    "    return tokens + [PAD_IDX] * (seq_length - len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e67a22ca-7c14-4740-8235-1ed5df6edef4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': functools.partial(<function _spacy_tokenize at 0x000002A2767F27A0>, spacy=<spacy.lang.de.German object at 0x000002A2070C6F80>),\n",
       " 'de': functools.partial(<function _spacy_tokenize at 0x000002A2767F27A0>, spacy=<spacy.lang.en.English object at 0x000002A20729C130>)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0da26bfd-1520-43a0-8914-bf6b2e736ff4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "en_trans = token_transform['en']\n",
    "en_voc_trans = vocab_transform['en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "514f167c-15bc-49ef-b543-bedb57b007c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'want', 'to', 'eat', 'bread']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_trans(toydata['en'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c729e08a-68c8-4589-87c8-de5385798843",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "139b42b6-36a3-4f46-939d-d91dcf5edd3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 11, 10, 8, 15]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_voc_trans(en_trans(toydata['en'].iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da8f70a4-c286-4418-829e-78369ddabda3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 11, 10, 8, 15, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_transform(en_voc_trans(en_trans(toydata['en'].iloc[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e9f237e-752e-4167-8ed5-12b5ad7ea524",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# helper function to club together sequential operations\n",
    "def sequential_transforms(*transforms):\n",
    "    def func(txt_input):\n",
    "        for transform in transforms:\n",
    "            txt_input = transform(txt_input)\n",
    "        return txt_input\n",
    "    return func\n",
    "\n",
    "# function to add BOS/EOS and create tensor for input sequence indices\n",
    "def tensor_transform(token_ids: List[int]):\n",
    "    return torch.cat((torch.tensor([BOS_IDX]),\n",
    "                      torch.tensor(token_ids),\n",
    "                      torch.tensor([EOS_IDX])))\n",
    "\n",
    "# ``src`` and ``tgt`` language text transforms to convert raw strings into tensors indices\n",
    "text_transform = {}\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    text_transform[ln] = sequential_transforms(token_transform[ln], #Tokenization\n",
    "                                               vocab_transform[ln], #Numericalization\n",
    "                                               pad_transform,\n",
    "                                               tensor_transform) # Add BOS/EOS and create tensor\n",
    "\n",
    "\n",
    "def pad_first_to_len(seqs, l):\n",
    "    seqs[0] += [0] * (l - len(seqs[0]))\n",
    "    \n",
    "# function to collate data samples into batch tensors\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src_sample, tgt_sample in batch:\n",
    "        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n",
    "        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
    "\n",
    "    # pad_first_to_len(src_batch, seq_length)\n",
    "    # pad_first_to_len(tgt_batch, seq_length)\n",
    "    \n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
    "    return src_batch, tgt_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3933728a-c7ce-4266-ae86-460421b7bc52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ToyData(split='train'):\n",
    "    if split == 'train':\n",
    "        return toydata.to_numpy()[:20]\n",
    "    elif split == 'valid':\n",
    "        return toydata.to_numpy()[20:30]\n",
    "    else:\n",
    "        return toydata.to_numpy()[30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "40605371-4454-4b17-8a99-74f9a3d98c94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train_epoch(model, optimizer):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "    # train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "    train_iter = ToyData(split='train')\n",
    "    train_dataloader = DataLoader(train_iter, batch_size=10, collate_fn=collate_fn)\n",
    "\n",
    "    for src, tgt in train_dataloader:\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        # logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "        # logits = model(src, tgt_input)\n",
    "        logits = model(src, tgt)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        # loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt.reshape(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(list(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "37544d88-cf9c-4b18-a9c4-34d77c3af6d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "\n",
    "    # val_iter = Multi30k(split='valid', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "    val_iter = ToyData(split='valid')\n",
    "    val_dataloader = DataLoader(val_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "    \n",
    "\n",
    "    for src, tgt in val_dataloader:\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        # logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "        # logits = model(src, tgt_input)\n",
    "        logits = model(src, tgt)\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        # loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt.reshape(-1))\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(list(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "411270e0-ec86-4cef-a170-dbe8c3b446d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n",
      "Epoch: 1, Train loss: 2.081, Val loss: 2.334, Epoch time = 7.127s\n",
      "Epoch: 2, Train loss: 2.073, Val loss: 2.332, Epoch time = 6.874s\n",
      "Epoch: 3, Train loss: 2.065, Val loss: 2.330, Epoch time = 6.817s\n",
      "Epoch: 4, Train loss: 2.063, Val loss: 2.327, Epoch time = 7.061s\n",
      "Epoch: 5, Train loss: 2.064, Val loss: 2.325, Epoch time = 7.026s\n",
      "Epoch: 6, Train loss: 2.062, Val loss: 2.323, Epoch time = 7.078s\n",
      "Epoch: 7, Train loss: 2.062, Val loss: 2.321, Epoch time = 7.120s\n",
      "Epoch: 8, Train loss: 2.061, Val loss: 2.319, Epoch time = 6.997s\n",
      "Epoch: 9, Train loss: 2.059, Val loss: 2.319, Epoch time = 6.950s\n",
      "Epoch: 10, Train loss: 2.060, Val loss: 2.319, Epoch time = 7.159s\n",
      "Epoch: 11, Train loss: 2.059, Val loss: 2.319, Epoch time = 7.096s\n",
      "Epoch: 12, Train loss: 2.052, Val loss: 2.318, Epoch time = 7.118s\n",
      "Epoch: 13, Train loss: 2.050, Val loss: 2.318, Epoch time = 7.255s\n",
      "Epoch: 14, Train loss: 2.053, Val loss: 2.321, Epoch time = 7.014s\n",
      "Epoch: 15, Train loss: 2.043, Val loss: 2.325, Epoch time = 7.141s\n",
      "Epoch: 16, Train loss: 2.044, Val loss: 2.327, Epoch time = 7.050s\n",
      "Epoch: 17, Train loss: 2.044, Val loss: 2.328, Epoch time = 6.974s\n",
      "Epoch: 18, Train loss: 2.043, Val loss: 2.329, Epoch time = 6.904s\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "NUM_EPOCHS = 18\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = timer()\n",
    "    train_loss = train_epoch(transformer, optimizer)\n",
    "    end_time = timer()\n",
    "    val_loss = evaluate(transformer)\n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "beb85da6-32e9-497f-8f40-6ecb9bf0a742",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n"
     ]
    }
   ],
   "source": [
    "# function to generate output sequence using greedy algorithm\n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    src = src.to(DEVICE)\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "\n",
    "    # memory = model.encode(src, src_mask)\n",
    "    memory = model.encode(src)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(DEVICE)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
    "                    .type(torch.bool)).to(DEVICE)\n",
    "        # out = model.decode(ys, memory, tgt_mask)\n",
    "        out = model.decode(ys, memory)\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.item()\n",
    "\n",
    "        ys = torch.cat([ys,\n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "\n",
    "# actual function to translate input sentence into target language\n",
    "def translate(model: torch.nn.Module, src_sentence: str):\n",
    "    model.eval()\n",
    "    src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n",
    "    num_tokens = src.shape[0]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    tgt = torch.ones(1, 1).fill_(BOS_IDX).type(torch.long).to(DEVICE)\n",
    "    # tgt_tokens = greedy_decode(\n",
    "    #     model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
    "    model.decode(src, tgt)\n",
    "    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884926c9-9445-4356-ae6c-aafec392f8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(transformer, open('transformer.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "952cdc5d-162f-444d-aacb-de5995a70ca6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[14, 1, 8, 64]' is invalid for input of size 512",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtranslate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoydata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43men\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[56], line 36\u001b[0m, in \u001b[0;36mtranslate\u001b[1;34m(model, src_sentence)\u001b[0m\n\u001b[0;32m     33\u001b[0m tgt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfill_(BOS_IDX)\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mlong)\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# tgt_tokens = greedy_decode(\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m#     model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(vocab_transform[TGT_LANGUAGE]\u001b[38;5;241m.\u001b[39mlookup_tokens(\u001b[38;5;28mlist\u001b[39m(tgt_tokens\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())))\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<bos>\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<eos>\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32me:\\workspace\\ProtFuncLang\\toy_transformer.py:377\u001b[0m, in \u001b[0;36mdecode\u001b[1;34m(self, src, trg)\u001b[0m\n\u001b[0;32m    356\u001b[0m     trg_mask = torch.tril(torch.ones((trg_len, trg_len))).expand(\n\u001b[0;32m    357\u001b[0m         batch_size, 1, trg_len, trg_len\n\u001b[0;32m    358\u001b[0m     )\n\u001b[0;32m    359\u001b[0m     return trg_mask\n\u001b[0;32m    361\u001b[0m # def decode(self, src, trg):\n\u001b[0;32m    362\u001b[0m #     \"\"\"\n\u001b[0;32m    363\u001b[0m #     for inference\n\u001b[0;32m    364\u001b[0m #     Args:\n\u001b[0;32m    365\u001b[0m #         src: input to encoder\n\u001b[0;32m    366\u001b[0m #         trg: input to decoder\n\u001b[0;32m    367\u001b[0m #     out:\n\u001b[0;32m    368\u001b[0m #         out_labels : returns final prediction of sequence\n\u001b[0;32m    369\u001b[0m #     \"\"\"\n\u001b[0;32m    370\u001b[0m #     trg_mask = self.make_trg_mask(trg)\n\u001b[0;32m    371\u001b[0m #     enc_out = self.encoder(src)\n\u001b[0;32m    372\u001b[0m #     out_labels = []\n\u001b[0;32m    373\u001b[0m #     batch_size, seq_len = src.shape[0], src.shape[1]\n\u001b[0;32m    374\u001b[0m #     # outputs = torch.zeros(seq_len, batch_size, self.target_vocab_size)\n\u001b[0;32m    375\u001b[0m #     out = trg\n\u001b[0;32m    376\u001b[0m #     for i in range(seq_len):  # 10\n\u001b[1;32m--> 377\u001b[0m #         out = self.decoder(out, enc_out, trg_mask)  # bs x seq_len x vocab_dim\n\u001b[0;32m    378\u001b[0m #         # taking the last token\n\u001b[0;32m    379\u001b[0m #         out = out[:, -1, :]\n\u001b[0;32m    380\u001b[0m #\n\u001b[0;32m    381\u001b[0m #         out = out.argmax(-1)\n\u001b[0;32m    382\u001b[0m #         out_labels.append(out.item())\n\u001b[0;32m    383\u001b[0m #         out = torch.unsqueeze(out, axis=0)\n\u001b[0;32m    384\u001b[0m #\n\u001b[0;32m    385\u001b[0m #     return out_labels\n\u001b[0;32m    387\u001b[0m def forward(self, src, trg):\n\u001b[0;32m    388\u001b[0m     \"\"\"\n\u001b[0;32m    389\u001b[0m     Args:\n\u001b[0;32m    390\u001b[0m         src: input to encoder\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         out: final vector which returns probabilities of each target word\n\u001b[0;32m    394\u001b[0m     \"\"\"\n",
      "File \u001b[1;32mg:\\.conda\\cuda11.8\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32me:\\workspace\\ProtFuncLang\\toy_transformer.py:310\u001b[0m, in \u001b[0;36mTransformerDecoder.forward\u001b[1;34m(self, x, enc_out, mask)\u001b[0m\n\u001b[0;32m    307\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m--> 310\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43menc_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    312\u001b[0m out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc_out(x))\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mg:\\.conda\\cuda11.8\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32me:\\workspace\\ProtFuncLang\\toy_transformer.py:265\u001b[0m, in \u001b[0;36mDecoderBlock.forward\u001b[1;34m(self, key, query, x, mask)\u001b[0m\n\u001b[0;32m    262\u001b[0m attention \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention(x, x, x, mask\u001b[38;5;241m=\u001b[39mmask)  \u001b[38;5;66;03m# 32x10x512\u001b[39;00m\n\u001b[0;32m    263\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(attention \u001b[38;5;241m+\u001b[39m x))\n\u001b[1;32m--> 265\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mg:\\.conda\\cuda11.8\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32me:\\workspace\\ProtFuncLang\\toy_transformer.py:192\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[1;34m(self, key, query, value)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, query, value):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;124;03m       key: key vector\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    189\u001b[0m \n\u001b[0;32m    190\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 192\u001b[0m     attention_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 32x10x512\u001b[39;00m\n\u001b[0;32m    193\u001b[0m     attention_residual_out \u001b[38;5;241m=\u001b[39m attention_out \u001b[38;5;241m+\u001b[39m value  \u001b[38;5;66;03m# 32x10x512\u001b[39;00m\n\u001b[0;32m    194\u001b[0m     norm1_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(attention_residual_out))  \u001b[38;5;66;03m# 32x10x512\u001b[39;00m\n",
      "File \u001b[1;32mg:\\.conda\\cuda11.8\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32me:\\workspace\\ProtFuncLang\\toy_transformer.py:119\u001b[0m, in \u001b[0;36mMultiHeadAttention.forward\u001b[1;34m(self, key, query, value, mask)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;66;03m# 32x10x512\u001b[39;00m\n\u001b[0;32m    117\u001b[0m key \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39mview(batch_size, seq_length, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_heads,\n\u001b[0;32m    118\u001b[0m                \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msingle_head_dim)  \u001b[38;5;66;03m# batch_size x sequence_length x n_heads x single_head_dim = (32x10x8x64)\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_length_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_heads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msingle_head_dim\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (32x10x8x64)\u001b[39;00m\n\u001b[0;32m    120\u001b[0m value \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mview(batch_size, seq_length, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msingle_head_dim)  \u001b[38;5;66;03m# (32x10x8x64)\u001b[39;00m\n\u001b[0;32m    122\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_matrix(key)  \u001b[38;5;66;03m# (32x10x8x64)\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[14, 1, 8, 64]' is invalid for input of size 512"
     ]
    }
   ],
   "source": [
    "translate(transformer, toydata.iloc[0]['en'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37772433-0aa1-489d-8bfa-5f25b20d7ad8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
